<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>SystemTap’s BPF Backend Introduces Tracepoint Support</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/pf_2vdFxk70/" /><category term="Announcement" /><category term="Developer Tools" /><category term="Performance" /><category term="Products" /><category term="Red Hat Developer Toolset" /><category term="bpf" /><category term="developer toolset" /><category term="performance" /><category term="performance monitoring" /><category term="systemtap" /><category term="tracing" /><author><name>Aaron Merey</name></author><id>https://developers.redhat.com/blog/?p=474927</id><updated>2018-04-23T10:55:07Z</updated><published>2018-04-23T10:55:07Z</published><content type="html">&lt;p&gt;This blog is the third in a series on stapbpf, SystemTap&amp;#8217;s BPF (Berkeley Packet Filter) backend. In the first post, &lt;a href="https://developers.redhat.com/blog/2017/12/13/introducing-stapbpf-systemtaps-new-bpf-backend/"&gt;Introducing stapbpf – SystemTap’s new BPF backend&lt;/a&gt;, I explain what BPF is and what features it brings to SystemTap. In the second post, &lt;a href="https://developers.redhat.com/blog/2017/12/15/bpf-maps-used-stapbpf/"&gt;What are BPF Maps and how are they used in stapbpf&lt;/a&gt;, I examine BPF maps, one of BPF&amp;#8217;s key components, and their role in stapbpf&amp;#8217;s implementation.&lt;/p&gt; &lt;p&gt;In this post, I introduce stapbpf&amp;#8217;s recently added support for tracepoint probes. Tracepoints are statically-inserted hooks in the Linux kernel onto which user-defined probes can be attached. Tracepoints can be found in a variety of locations throughout the Linux kernel, including performance-critical subsystems such as the scheduler. Therefore, tracepoint probes must terminate quickly in order to avoid significant performance penalties or unusual behavior in these subsystems. BPF&amp;#8217;s lack of loops and limit of 4k instructions means that it&amp;#8217;s sufficient for this task.&lt;span id="more-474927"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Using tracepoint probes with stapbpf&lt;/h2&gt; &lt;p&gt;SystemTap makes it easy for users to write BPF programs and attach them to tracepoints. SystemTap&amp;#8217;s high-level scripting language provides a straightforward way to interface with the kernel&amp;#8217;s BPF facilities. The following example script attaches a probe to the &lt;code&gt;mm_filemap_add_to_page_cache&lt;/code&gt; tracepoint. It tracks how many pages are added by each process and which process has added the most pages. Once the tracepoint probe has been running for 30 seconds, the timer probe (also a BPF program) fires and the process that added the most pages is printed along with the number of pages it added. Probing is then terminated via &lt;code&gt;exit()&lt;/code&gt;.&lt;/p&gt; &lt;pre&gt;$ cat example.stp global faults[250] global max = -1 probe kernel.trace("mm_filemap_add_to_page_cache") { faults[pid()]++ if (max == -1 || faults[pid()] &amp;#62; faults[max]) max = pid() } probe timer.s(30) { if (max != -1) printf("Pid %d added %d pages\n", max, faults[max]) else printf("No page cache adds detected\n") exit() } &lt;/pre&gt; &lt;p&gt;To run this script using stapbpf, simply use &lt;code&gt;stap --bpf&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;# stap --bpf example.stp Pid 5099 added 5894 pages &lt;/pre&gt; &lt;h2&gt;Advantages of stapbpf&lt;/h2&gt; &lt;p&gt;SystemTap&amp;#8217;s scripting language conveniently abstracts away a variety of low-level BPF details that may not be pertinent to a user&amp;#8217;s inquiry and could complicate their investigation or at least worsen the learning curve associated with BPF tooling. Actions such as declaring a hashmap with space for 250 key-value pairs (&lt;code&gt;global fault[250]&lt;/code&gt;) and checking whether it contains a specific key (&lt;code&gt;pid() in fault&lt;/code&gt;) are very simple to express in SystemTap. If other BPF tools are used, then performing these actions may require increased verbosity or additional knowledge of BPF internals such as the various types of BPF maps and which kernel-provided BPF helper functions should be used to correctly access the map.&lt;/p&gt; &lt;p&gt;Stapbpf is also able to create tracepoint probes for kernel builds that differ from the system on which it&amp;#8217;s currently running (the host machine). This can be useful for cases where the target machine requires minimal tooling or where probes must be compiled for modules that have not yet been loaded into the kernel. In order to cross-compile the probes, stapbpf derives tracepoint information directly from kernel header files of the target machine.&lt;/p&gt; &lt;p&gt;To do so, stapbpf uses an interesting technique adapted from SystemTap&amp;#8217;s default (loadable kernel module) runtime. Kernel header files containing tracepoint definitions are compiled along with additional headers created by SystemTap. These SystemTap-specific headers modify tracepoint definition macros so that debug info found in the resulting modules contains the information needed to construct the probes. In particular, stapbpf requires the size of the tracepoint arguments and their location during probe execution so that these arguments can be properly accessed. SystemTap also uses this technique to implement typecasting via the &lt;code&gt;@cast&lt;/code&gt; operator. This allows users of stapbpf to cast void pointer context variables to a type that can be dereferenced:&lt;/p&gt; &lt;pre&gt;probe kernel.trace("hrtimer_init") { state = @cast($hrtimer, "hrtimer", "kernel&amp;#60;linux/hrtimer.h&amp;#62;")-&amp;#62;state printf("hrtimer state: %d\n", state) }&lt;/pre&gt; &lt;p&gt;Cross-compiling requires having the target machine&amp;#8217;s kernel build tree on the host machine and the stapbpf binary on the target machine. Then it&amp;#8217;s just a matter of using &lt;code&gt;stap --remote&lt;/code&gt; to compile the probes locally and run them on the target machine via SSH:&lt;/p&gt; &lt;pre&gt;# stap --bpf --remote ssh://user@hostname example.stp Pid 8346 added 89 pages &lt;/pre&gt; &lt;h2&gt;Where to get SystemTap&lt;/h2&gt; &lt;p&gt;Stapbpf development is ongoing so it&amp;#8217;s recommended that you build and install SystemTap using the most up-to-date source code. Instructions for doing so can be found &lt;a href="https://sourceware.org/git/?p=systemtap.git;a=blob_plain;f=README;hb=HEAD"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;linkname=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F23%2Fsystemtaps-bpf-backend-tracepoint-support%2F&amp;#38;title=SystemTap%E2%80%99s%20BPF%20Backend%20Introduces%20Tracepoint%20Support" data-a2a-url="https://developers.redhat.com/blog/2018/04/23/systemtaps-bpf-backend-tracepoint-support/" data-a2a-title="SystemTap’s BPF Backend Introduces Tracepoint Support"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/23/systemtaps-bpf-backend-tracepoint-support/"&gt;SystemTap&amp;#8217;s BPF Backend Introduces Tracepoint Support&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/pf_2vdFxk70" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This blog is the third in a series on stapbpf, SystemTap&amp;#8217;s BPF (Berkeley Packet Filter) backend. In the first post, Introducing stapbpf – SystemTap’s new BPF backend, I explain what BPF is and what features it brings to SystemTap. In the second post, What are BPF Maps and how are they used in stapbpf, I [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/23/systemtaps-bpf-backend-tracepoint-support/"&gt;SystemTap&amp;#8217;s BPF Backend Introduces Tracepoint Support&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/23/systemtaps-bpf-backend-tracepoint-support/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">474927</post-id><dc:creator>Aaron Merey</dc:creator><dc:date>2018-04-23T10:55:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/23/systemtaps-bpf-backend-tracepoint-support/</feedburner:origLink></entry><entry><title>jBPM Work Items are really simple!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/OhlQTJ0ooRw/jbpm-work-items-are-really-simple.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Maciej Swiderski</name></author><id>searchisko:content:id:jbossorg_blog-jbpm_work_items_are_really_simple</id><updated>2018-04-23T10:34:15Z</updated><published>2018-04-23T10:34:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Work items are the way to build custom (domain specific) services that can be used from within a process. They are as any other activity in the process with the difference that they are usually focused on given domain or area.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-F8FRKUh6tIk/Wt2qQ61aD3I/AAAAAAAABbo/aTL283CxKRUAaRRF7DwXrns0w1d0Qh5YQCLcBGAs/s1600/Screen%2BShot%2B2018-04-23%2Bat%2B11.40.53.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="727" data-original-width="1600" height="290" src="https://3.bp.blogspot.com/-F8FRKUh6tIk/Wt2qQ61aD3I/AAAAAAAABbo/aTL283CxKRUAaRRF7DwXrns0w1d0Qh5YQCLcBGAs/s640/Screen%2BShot%2B2018-04-23%2Bat%2B11.40.53.png" width="640" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;Work Items are by default placed under Service Tasks category on the palette so can be easily drag and dropped into the canvas when designing processes and cases. Location on the palette is also configurable via category property of the work item definition. So let's have a guided tour on how to create a very simple but functional work item.&lt;br /&gt;&lt;br /&gt;The complete process consists of following steps:&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;generating maven project for work item (both definition and handler)&lt;/li&gt;&lt;li&gt;implementing handler and configuring work item&lt;/li&gt;&lt;li&gt;optionally provide custom icon (16x16)&lt;/li&gt;&lt;li&gt;add work item project into service repository&lt;/li&gt;&lt;li&gt;import work item into project in workbench&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Let's get our hands dirty and implement simple work item and then use it in a process.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Generate work item maven project&lt;/h3&gt;&lt;div&gt;First step is to generate maven project that will be our base for:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;work item definition&lt;/li&gt;&lt;li&gt;work item handler&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;First things first, what is work item definition and what is work item handler?&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Work Item definition&lt;/b&gt; is a description of the work to be done. That is usually described by unique name, description, to make it more visible on the diagram - an icon and then what is expected at the entry (data inputs - parameters) and what is expected at the exit (data output - results).&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Work Item handler&lt;/b&gt; is a logic that will be actually executed when given activity (representing work item) will be triggered as part of the process instance execution.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Work Item is then a runtime representation of the Work Item definition that is backed by Work Item handler that is registered in the process engine via Work Item name. This registration gives users additional flexibility to allow usage of different logic to be executed depending where the process is executed - test vs production environment.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;So to generate a maven project use maven archetype&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;pre class="brush:java"&gt;mvn archetype:generate \&lt;br /&gt;-DarchetypeGroupId=org.jbpm \&lt;br /&gt;-DarchetypeArtifactId=jbpm-workitems-archetype \&lt;br /&gt;-DarchetypeVersion=7.8.0-SNAPSHOT \&lt;br /&gt;-DgroupId=org.jbpm.contrib \&lt;br /&gt;-DartifactId=custom-workitem \&lt;br /&gt;-DclassPrefix=Custom \&lt;br /&gt;-Dversion=7.8.0-SNAPSHOT \&lt;br /&gt;-DarchetypeCatalog=local&lt;br /&gt;&lt;/pre&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;This command will generate a new project with:&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;groupId - org.jbpm.contrib&lt;/li&gt;&lt;li&gt;artifactId - custom-workitem&lt;/li&gt;&lt;li&gt;version - 7.8.0-SNAPSHOT&lt;/li&gt;&lt;li&gt;with work item configuration and handler class&amp;nbsp;custom-workitem/src/main/java/org/jbpm/contrib/CustomWorkItemHandler.java&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;i&gt;I'd like to recommend to generate this project as part of the official jbpm-work-items repository to benefit from service repository included in there. The rest of the article will assume this has been done.&amp;nbsp;&lt;/i&gt;&lt;br /&gt;&lt;i&gt;If you haven't done it yet, follow these:&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;i&gt;clone github project:&amp;nbsp;https://github.com/kiegroup/jbpm-work-items&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;go into jbpm-work-items&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;check the version number of the cloned project and adjust version argument accordingly in the maven archetype:generate command&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once the project is generated, import it into your IDE and implement the handler - CustomWorkItemHandler.java. You might need to add additional dependencies to your project, depending your the implementation - when doing so please keep following in mind:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;dependencies that are already included in KIE Server - mark them as provided&lt;/li&gt;&lt;li&gt;check for any conflicts with application server, KIE Server and your app dependencies and resolve them - either by adjusting your handler project dependencies or runtime environment&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;CustomWorkItemHandler.java class consists of &lt;a href="https://github.com/kiegroup/jbpm/blob/master/jbpm-workitems/jbpm-workitems-core/src/main/java/org/jbpm/process/workitem/core/util/Wid.java"&gt;@Wid&lt;/a&gt; annotation that is actually responsible for configuring your work item definition. It allows you to define (to name just few):&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;name&lt;/li&gt;&lt;li&gt;description&lt;/li&gt;&lt;li&gt;category&lt;/li&gt;&lt;li&gt;icon&lt;/li&gt;&lt;li&gt;input parameters&lt;/li&gt;&lt;li&gt;results&lt;/li&gt;&lt;li&gt;handler&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;Most of the important parts are already generated for you, so examine them and check for correctness. Most likely parameters and results will be the one most often changed when implementing handlers.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once that is done, proceed with implementation of the executeWorkItem method which is the heart of your custom work item.&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Expose your work item in Service Repository&lt;/h3&gt;Now to take advantage of repository generation of jbpm-work-items project you need to add your newly generated project into two pom files:&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;main pom.xml file of jbpm-work-items project - one regular and one zip dependency&lt;/li&gt;&lt;div&gt;&lt;pre class="brush:java"&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt; &amp;lt;groupId&amp;gt;org.jbpm.contrib&amp;lt;/groupId&amp;gt;&lt;br /&gt; &amp;lt;artifactId&amp;gt;custom-workitem&amp;lt;/artifactId&amp;gt;&lt;br /&gt; &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;&lt;br /&gt; &amp;lt;/dependency&amp;gt;&lt;br /&gt; &amp;lt;dependency&amp;gt;&lt;br /&gt; &amp;lt;groupId&amp;gt;org.jbpm.contrib&amp;lt;/groupId&amp;gt;&lt;br /&gt; &amp;lt;artifactId&amp;gt;custom-workitem&amp;lt;/artifactId&amp;gt;&lt;br /&gt; &amp;lt;version&amp;gt;${project.version}&amp;lt;/version&amp;gt;&lt;br /&gt; &amp;lt;type&amp;gt;zip&amp;lt;/type&amp;gt;&lt;br /&gt; &amp;lt;/dependency&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;/div&gt;&lt;li&gt;repository/pom.xml - only zip dependency (but this time without the version tag)&lt;/li&gt;&lt;div&gt;&lt;pre class="brush:java"&gt;&amp;lt;dependency&amp;gt;&lt;br /&gt; &amp;lt;groupId&amp;gt;org.jbpm.contrib&amp;lt;/groupId&amp;gt;&lt;br /&gt; &amp;lt;artifactId&amp;gt;custom-workitem&amp;lt;/artifactId&amp;gt;&lt;br /&gt; &amp;lt;type&amp;gt;zip&amp;lt;/type&amp;gt;&lt;br /&gt; &amp;lt;/dependency&amp;gt;&lt;br /&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;When you're finished just build the project (assuming you're in jbpm-work-items repository) use following:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;pre class="brush:java"&gt;mvn clean install -DskipTests -rf :custom-workitem&lt;br /&gt;&lt;/pre&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;this will then build your project (custom-work item - adjust it if the artifactId is different) and repositories. Then if you start SpringBoot based Service Repository&lt;br /&gt;&lt;br /&gt;&lt;pre class="brush:java"&gt;java -jar repository-springboot/target/repository-springboot-7.8.0-SNAPSHOT.jar&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;you'll have your work item available there, just go to &lt;a href="http://localhost:8090/repository"&gt;http://localhost:8090/repository&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;And that's it, you have your work item implemented, built and exposed via Service Repository!!!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Use work item in workbench&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;To make use of your newly created work item, login to workbench and:&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;create project&lt;/li&gt;&lt;li&gt;create asset - Business Process&lt;/li&gt;&lt;li&gt;use the yellow repository icon in the designer menu to open service repository browser&lt;/li&gt;&lt;li&gt;select work item and install it&lt;/li&gt;&lt;li&gt;reopen process editor and you'll find your installed work item under Service Tasks category (unless you changed the category when implementing work item)&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;That's all you need, in the background when the work item was installed your project was modified to add:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;dependency to your work item jar (as maven dependency of your workbench's project)&lt;/li&gt;&lt;li&gt;deployment descriptor to register work item handler&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;So now you're ready to launch it - just build and deploy your project in workbench and enjoy your work item being executed.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;All this in single screen cast can be found below&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/QO-iboWDXVs" width="560"&gt;&lt;/iframe&gt; &lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/OhlQTJ0ooRw" height="1" width="1" alt=""/&gt;</content><summary>Work items are the way to build custom (domain specific) services that can be used from within a process. They are as any other activity in the process with the difference that they are usually focused on given domain or area. Work Items are by default placed under Service Tasks category on the palette so can be easily drag and dropped into the canvas when designing processes and cases. Location o...</summary><dc:creator>Maciej Swiderski</dc:creator><dc:date>2018-04-23T10:34:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/04/jbpm-work-items-are-really-simple.html</feedburner:origLink></entry><entry><title>Data set editor for KIE Server custom queries</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/i_QF7FBOgFk/data-set-editor-for-kie-server-custom.html" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><author><name>Maciej Swiderski</name></author><id>searchisko:content:id:jbossorg_blog-data_set_editor_for_kie_server_custom_queries</id><updated>2018-04-23T07:30:14Z</updated><published>2018-04-23T07:30:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;a href="http://mswiderski.blogspot.com/2016/01/advanced-queries-in-kie-server.html"&gt;Custom queries feature in KIE Server&lt;/a&gt; has been out for quite a while and proved to be very useful. Although there was no integration with workbench to take advantage of when:&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;working with subset of data from various tables that are not exposed via runtime views (processes or tasks)&lt;/li&gt;&lt;li&gt;building data set entries for reporting purpose&lt;/li&gt;&lt;li&gt;building dashboards&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;With version 7.8, jBPM is now equipped with data set editor for KIE Server custom queries, it allows users to:&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;define (as data set) and test queries on remote KIE Servers&lt;/li&gt;&lt;li&gt;save and edit existing data sets&amp;nbsp;&lt;/li&gt;&lt;li&gt;use defined data sets when building dashboards via Pages feature of workbench&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;Moreover, data set editor for KIE Server queries is built in a way that it ensures that queries are always send to all known kie servers when using managed mode. New KIE Servers connecting to controller (workbench) will also receive custom queries defined via data set editor.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;See all this in action in short screencast&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;iframe allow="autoplay; encrypted-media" allowfullscreen="" frameborder="0" height="315" src="https://www.youtube.com/embed/lnFTJZK70Ac" width="560"&gt;&lt;/iframe&gt; &lt;div&gt;&lt;br /&gt;As usual, comments are more than welcome&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/i_QF7FBOgFk" height="1" width="1" alt=""/&gt;</content><summary>Custom queries feature in KIE Server has been out for quite a while and proved to be very useful. Although there was no integration with workbench to take advantage of when: working with subset of data from various tables that are not exposed via runtime views (processes or tasks) building data set entries for reporting purpose building dashboards With version 7.8, jBPM is now equipped with data s...</summary><dc:creator>Maciej Swiderski</dc:creator><dc:date>2018-04-23T07:30:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/04/data-set-editor-for-kie-server-custom.html</feedburner:origLink></entry><entry><title>Hibernate Community Newsletter 08/2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/br24oV9O4LY/" /><category term="Discussions" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="newsletter" scheme="searchisko:content:tags" /><author><name>Vlad Mihalcea</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_community_newsletter_08_2018</id><updated>2018-04-23T11:06:54Z</updated><published>2018-04-23T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="articles"&gt;&lt;a class="anchor" href="#articles"&gt;&lt;/a&gt;Articles&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A very good resource especially for beginners, &lt;a href="https://www.theserverside.com/tip/How-JPA-and-Hibernate-simplify-data-persistence"&gt;this article&lt;/a&gt; shows you how JPA and Hibernate simplify data persistence.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When using JPA and Hibernate, it is very important to log the statements that are auto-generated on your behalf. If you are using Spring Boot, check out &lt;a href="http://www.baeldung.com/sql-logging-spring-boot"&gt;this article&lt;/a&gt; for more details about enabling SQL statement logging.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A very good addition to the PostgreSQL JDBC Driver, the &lt;code&gt;reWriteBatchedInserts&lt;/code&gt; configuration property allows you to optimize the processing of batched statements on the database side. For more details, check out &lt;a href="https://vladmihalcea.com/postgresql-multi-row-insert-rewritebatchedinserts-property/"&gt;this article&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you want to use Hibernate with SAP HANA on Google Cloud Platform, then &lt;a href="https://blogs.sap.com/2018/04/09/building-translytical-applications-using-hibernate-sap-hana-and-google/"&gt;this tutorial&lt;/a&gt; provides a very good introduction about how you can build translytical applications.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;If you’re using PostgreSQL with JPA and Hibernate, these &lt;a href="https://vladmihalcea.com/9-postgresql-high-performance-performance-tips/"&gt;9 High-Performance Tips&lt;/a&gt; will surely help you speed up your data access layer.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Iif you want to use Spring Boot to build an application that uses Hibernate to persist data into Oracle &lt;a href="http://programmergate.com/spring-boot-jpa-hibernate-oracle/"&gt;this tutorial&lt;/a&gt; will provide a step-by-step guide for how to achieve this goal.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Most often, a JPA is mapped to a one database table. Nevertheless, you can also map &lt;a href="https://vladmihalcea.com/the-best-way-to-lazy-load-entity-attributes-using-jpa-and-hibernate/"&gt;multiple entities to the same database table&lt;/a&gt; or &lt;a href="https://www.thoughts-on-java.org/hibernate-tips-how-to-map-an-entity-to-multiple-tables/"&gt;an entity to multiple tables&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="time-to-upgrade"&gt;&lt;a class="anchor" href="#time-to-upgrade"&gt;&lt;/a&gt;Time to upgrade&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;There were two Hibernate project releases since the last newsletter:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://in.relation.to/2018/04/17/hibernate-ogm-5-4-Alpha1-released/"&gt;Hibernate OGM 5.4.0.Alpha1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://in.relation.to/2018/04/13/hibernate-search-5-10-0-Beta2/"&gt;Hibernate Search 5.10.0.Beta2&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="questions-and-answers"&gt;&lt;a class="anchor" href="#questions-and-answers"&gt;&lt;/a&gt;Questions and answers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.quora.com/What%E2%80%99s-the-best-way-to-learn-Hibernate-ORM"&gt;What’s the best way to learn Hibernate ORM?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/entities-generated-by-hibernate-tools-fail-hbm2ddl-validation-schema-validation-wrong-column-type-encountered-in-column-found-mediumtext-types-longvarchar-but-expecting-longtext-types-varchar/525"&gt;Entities generated by Hibernate Tools fail hbm2ddl validation: schema-validation: wrong column type encountered in column found mediumtext (Types#LONGVARCHAR), but expecting longtext (Types#VARCHAR)&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-5-throws-duplicate-generator-name-xxx/534/2"&gt;Hibernate 5 throws duplicate generator name XXX&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/nativequery-with-entitygraphs-causes-a-classcastexception/532"&gt;NativeQuery with EntityGraphs causes a ClassCastException&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/27456242/what-is-the-use-of-hibernate-batch-processing/49778698#49778698"&gt;What is the use of Hibernate batch processing&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-throws-cannot-do-an-operation-on-a-closed-statement-on-mariadb/558"&gt;Hibernate throws “Cannot do an operation on a closed statement” on MariaDB&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/49878227/how-to-close-open-a-new-hibernate-session-in-case-of-exception/49878611#49878611"&gt;How to close &amp;amp; open a new Hibernate Session in case of Exception&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/first-level-cache-and-concurrency-control-when-using-jpa-and-hibernate/570"&gt;First-level cache and concurrency control when using JPA and Hibernate &lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/21257819/what-is-difference-between-hibernate-jdbc-fetch-size-and-hibernate-jdbc-batch-si/48129503#48129503"&gt;What is difference between hibernate.jdbc.fetch_size and hibernate.jdbc.batch_size?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/javax-persistence-persistenceexception-org-hibernate-exception-genericjdbcexception-unable-to-acquire-jdbc-connection/578/4?u=vlad"&gt;#Hibernate throws javax.persistence.PersistenceException: org.hibernate.exception.GenericJDBCException: Unable to acquire JDBC Connection&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/persist-dynamically-typed-entity-properties-with-hibernate-and-postgresql/589"&gt;Persist dynamically typed entity properties with Hibernate and PostgreSQL&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/retained-mutableentityentry-leak-in-entity-context-causes-application-hang/571/2"&gt;Retained MutableEntityEntry leak in entity context causes application to freeze&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/br24oV9O4LY" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users. Articles A very good resource especially for beginners, this article shows you how JPA and Hibernate simplify data persistence. When using JPA and Hibernate, it is very important to log the statements that are auto-generated on your behalf. If yo...</summary><dc:creator>Vlad Mihalcea</dc:creator><dc:date>2018-04-23T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/04/23/hibernate-community-newsletter-2018-08/</feedburner:origLink></entry><entry><title>Teiid 10.2.1 Released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_2iHhnXsYgc/teiid-1021-released.html" /><category term="feed_group_name_teiid" scheme="searchisko:content:tags" /><category term="feed_name_teiid" scheme="searchisko:content:tags" /><author><name>Steven Hawkins</name></author><id>searchisko:content:id:jbossorg_blog-teiid_10_2_1_released</id><updated>2018-04-20T17:55:56Z</updated><published>2018-04-20T17:55:00Z</published><content type="html">Teiid 10.2.1 has been &lt;a href="http://teiid.jboss.org/downloads/"&gt;released&lt;/a&gt;. It resolves 12 issues:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5293"&gt;TEIID-5293&lt;/a&gt;] - Add implicit partitioning of joins to non-multisource partitioning as well &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5220"&gt;TEIID-5220&lt;/a&gt;] - Add support for information_schema namespace &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5294"&gt;TEIID-5294&lt;/a&gt;] - Bug with the name correction logic (TEIID30151 eror) &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5296"&gt;TEIID-5296&lt;/a&gt;] - With MongoDB, timestamp operations throw exceptions when called on null or missing values &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5297"&gt;TEIID-5297&lt;/a&gt;] - With MongoDB, null is returned from timestamp functions if the same function is part of WHERE clause &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5300"&gt;TEIID-5300&lt;/a&gt;] - ClassCastException during query Optimization &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5310"&gt;TEIID-5310&lt;/a&gt;] - updateMatView does not check for null validity &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5312"&gt;TEIID-5312&lt;/a&gt;] - NullPointerException thrown when the second time login via GSS API &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5313"&gt;TEIID-5313&lt;/a&gt;] - Oracle translator issue with mixing string types and general issues with non-ascii strings &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5315"&gt;TEIID-5315&lt;/a&gt;] - MATVIEW_MAX_STALENESS_PCT reloads only based upon ttl &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5319"&gt;TEIID-5319&lt;/a&gt;] - SAP IQ translator wrong pushdown of query with multiple JOINs &lt;/li&gt;&lt;li&gt;[&lt;a href="https://issues.jboss.org/browse/TEIID-5320"&gt;TEIID-5320&lt;/a&gt;] - SAP IQ translator wrong pushdown of dateadd function &lt;/li&gt;&lt;/ul&gt;If you have time please check out the latest 10.3 snapshot. We are about half way mark in the cycle.&amp;nbsp; &lt;br /&gt;&lt;br /&gt;Thanks,&lt;br /&gt;Steve&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_2iHhnXsYgc" height="1" width="1" alt=""/&gt;</content><summary>Teiid 10.2.1 has been released. It resolves 12 issues: [TEIID-5293] - Add implicit partitioning of joins to non-multisource partitioning as well [TEIID-5220] - Add support for information_schema namespace [TEIID-5294] - Bug with the name correction logic (TEIID30151 eror) [TEIID-5296] - With MongoDB, timestamp operations throw exceptions when called on null or missing values [TEIID-5297] - With Mo...</summary><dc:creator>Steven Hawkins</dc:creator><dc:date>2018-04-20T17:55:00Z</dc:date><feedburner:origLink>http://teiid.blogspot.com/2018/04/teiid-1021-released.html</feedburner:origLink></entry><entry><title>Elytron: A New Security Framework in WildFly/JBoss EAP</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/01PxDs6LkS0/" /><category term="Red Hat JBoss Enterprise Application Platform" /><category term="Security" /><category term="eap" /><category term="eap-7" /><category term="EAP7" /><category term="Elytron" /><category term="jboss" /><category term="WildFly" /><author><name>Siddhartha De</name></author><id>https://developers.redhat.com/blog/?p=476417</id><updated>2018-04-20T10:55:41Z</updated><published>2018-04-20T10:55:41Z</published><content type="html">&lt;p&gt;&lt;a href="https://developer.jboss.org/wiki/WildFlyElytron-ProjectSummary"&gt;Elytron&lt;/a&gt; is a new security framework that ships with &lt;a href="http://wildfly.org/"&gt;WildFly&lt;/a&gt; version 10 and Red Hat JBoss Enterprise Application Platform (EAP) 7.1. This project is a complete replacement of &lt;a href="http://picketbox.jboss.org"&gt;PicketBox&lt;/a&gt; and JAAS. Elytron is a single security framework that will be usable for securing management access to the server and for securing applications deployed in WildFly. You can still use the legacy security framework, which is PicketBox, but it is a deprecated module; hence, there is no guarantee that PicketBox will be included in future releases of WildFly. In this article, we will explore the components of Elytron and how to configure them in Wildfly.&lt;/p&gt; &lt;p&gt;The Elytron project covers the following:&lt;b&gt; &lt;/b&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;SSL/TLS&lt;/li&gt; &lt;li&gt;Secure credential storage&lt;/li&gt; &lt;li&gt;Authentication&lt;/li&gt; &lt;li&gt;Authorization&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In this article, we are going to explore using SSL/TLS in WildFly with Elytron.&lt;span id="more-476417"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;This is the basic architecture of SSL/TLS in Elytron:&lt;/p&gt; &lt;p&gt;&lt;img class="alignnone wp-image-438042 size-large" src="https://docs.jboss.org/author/download/attachments/110231576/SSLContext.png?version=3&amp;#38;modificationDate=1474306442000" alt="" width="640" height="39" /&gt;&lt;/p&gt; &lt;p&gt;The key attribute here is &lt;code&gt;SSLContext&lt;/code&gt;, which also has the reference the following component:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Key-Manager:&lt;/b&gt;  key-manager keeps the reference of key-store to be used and load the keys.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Trust-Manager: &lt;/b&gt;This also keeps the reference of key-store, basically used for &lt;code&gt;trustCertificates&lt;/code&gt;. If all the certificates are present in the keystore referenced by key-manager, configuring trust-manager is not required. However, for outbound connections, a trust-manager can be used.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Security-Domain:&lt;/b&gt; This is an optional parameter,  However, if &lt;code&gt;SSLContext&lt;/code&gt; is configured with a reference to a security-domain, then the verification of a client&amp;#8217;s certificate can be performed as an authentication, thus ensuring the appropriate permissions for a login are assigned before even allowing the connection to be fully opened.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;code&gt;SSLContext&lt;/code&gt; also defines the type of SSL communication (one-way/two-way) along with allowed protocol and cipher-suite details.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Configure the SSLContext to Be Used by the Management Interface and the Undertow Subsytem &lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Before, we start configuring SSL/TLS in Elytron, we should have a certificate. In this tutorial, we will create a self-signed certificate to understand how SSL/TLS works in Elytron.&lt;/p&gt; &lt;p&gt;To manage the certificate/keystore, I have used here &lt;code&gt;keytool&lt;/code&gt; CLI-based utility that ships with Java. However, one can manage the certificate/keystore using another utility, such as  &lt;a href="http://portecle.sourceforge.net/"&gt;Portecle&lt;/a&gt;, which allows to manage the keystore/certificate graphically and does not require to remember long command lines.&lt;/p&gt; &lt;p&gt;First, use &lt;code&gt;keytool&lt;/code&gt; to generate the keystore and a self-signed certificate, executing a command similar to the following in the OS terminal command line:&lt;/p&gt; &lt;pre&gt;keytool -genkeypair -alias wildfly -keyalg RSA -sigalg SHA256withRSA -validity 365 -keysize 2048 -keypass jboss@123 -storepass jboss@123 -dname "CN=developer.jboss.org, C=IN" -ext san=dns:developers.redhat.org,dns:developers.wildfly.org -keystore wildfly.jks&lt;/pre&gt; &lt;p&gt;Note: This is just an example, you need to change the common name (CN) and other attribute as per your organization requirement and set the password accordingly.&lt;/p&gt; &lt;p&gt;Once we are ready with the certificate/keystore, need to perform the following steps to configure the Elytron subsystem for enabling SSL/TLS. Here, I am demonstrating the configuration using the JBoss CLI.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;First, we need to connect to the JBoss CLI&lt;strong&gt; &lt;/strong&gt;by executing the &lt;a href="https://docs.jboss.org/author/display/WFLY/Command+Line+Interface"&gt;jboss-cli&lt;/a&gt; command available in the directory &lt;code&gt;$WildFly_Home/bin&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;ul&gt; &lt;li&gt;Next, configure a &lt;code&gt;key-store&lt;/code&gt; component in the Elytron subsystem with the newly created keystore (here &lt;code&gt;wildfly.jks&lt;/code&gt; is placed at &lt;code&gt;$WildFly_Home/ssl&lt;/code&gt;).&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;/subsystem=elytron/key-store=wildflyKS:add(type=JKS,path="${jboss.home.dir}/ssl/wildfly.jks",credential-reference={clear-text=jboss@123})&lt;/pre&gt; &lt;ul&gt; &lt;li&gt;Then, create a new &lt;code&gt;key-manager&lt;/code&gt; component in the Elytron subsystem referencing the &lt;code&gt;key-store&lt;/code&gt; component created above. To do this, need to execute the command like below:&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;/subsystem=elytron/key-manager=wildflyKM:add(algorithm=SunX509,key-store=wildflyKS,credential-reference={clear-text=jboss@123})&lt;/p&gt; &lt;p&gt;Note: We are required to give the password (e.g. jboss@123) of keystore here while creating key-manager.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Finally, configure a new &lt;code&gt;server-ssl-context&lt;/code&gt; referencing the &lt;code&gt;key-manager&lt;/code&gt; component created in the previous step:&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;/subsystem=elytron/server-ssl-context=wildlfySSC:add(key-manager=wildflyKM,protocols=[TLSv1.2])&lt;/pre&gt; &lt;p&gt;To enable SSL/TLS through Elytron, we are required to execute the following two commands to configure the Undertow &lt;code&gt;https-listener&lt;/code&gt; and map the &lt;code&gt;ssl-context&lt;/code&gt; with Elytron. By default, the &lt;code&gt;https-listener&lt;/code&gt; is configured with the ApplicationRealm security realm, and by default, ApplicationRealm generates a self-signed certificate during the first startup of WildFly. You need to do batch execution, because both of the commands have to execute simultaneously, else you can remove the https-listener and add the https-listener again with ssl-context &lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt; &lt;pre&gt;batch /subsystem=undertow/server=default-server/https-listener=https:undefine-attribute(name=security-realm) /subsystem=undertow/server=default-server/https-listener=https:write-attribute(name=ssl-context,value=wildlfySSC) run-batch&lt;/pre&gt; &lt;p&gt;Now for the management interface to use the same &lt;code&gt;ssl-context&lt;/code&gt;, we need to execute the following commands in the JBoss CLI, which will also enable SSL for the management interface:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Before, configuring &lt;code&gt;ssl-context&lt;/code&gt; for the management-interface, we need to configure &lt;code&gt;secure-port&lt;/code&gt; for the management-http interface for communicating over SSL/TLS&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;/core-service=management/management-interface=http-interface:write-attribute(name=secure-socket-binding,value=management-https)&lt;/pre&gt; &lt;ul&gt; &lt;li&gt;Map the same &lt;code&gt;ssl-context&lt;/code&gt; with management-http interface for enabling SSL/TLS&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;/core-service=management/management-interface=http-interface:write-attribute(name=ssl-context,value=wildflySSC)&lt;/pre&gt; &lt;p&gt;Now, to test your configuration and the SSL/TLS handshake, make a request over the HTTPS protocol using your browser. To do this, you can also use the &lt;code&gt;openssl&lt;/code&gt; command-line utility, for example:&lt;/p&gt; &lt;pre&gt;openssl s_client -connect developers.redhat.com:8443&lt;/pre&gt; &lt;p&gt;You can also use the  &lt;a href="https://developers.redhat.com/blog/2017/10/27/ssl-testing-tool"&gt;SSL testing tool&lt;/a&gt; to check the certificate and the allowed protocol and ciphers. Once you have completed the setup, you can make your system live for the production usage.&lt;/p&gt; &lt;p&gt;There are couple of features in Elytron that were not there in earlier JBoss versions:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Elytron prints a warning message in the log upon expiration of the certificate used in the Elytron subsystem.&lt;/li&gt; &lt;li&gt;It is possible to load the certificate keystore without restarting/reloading the instance, although there are still some challenges.&lt;/li&gt; &lt;li&gt;Elytron also provides the facility to check the certificate details.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;linkname=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F20%2Felytron-new-security-framework-wildfly-jboss-eap%2F&amp;#38;title=Elytron%3A%20A%20New%20Security%20Framework%20in%20WildFly%2FJBoss%20EAP" data-a2a-url="https://developers.redhat.com/blog/2018/04/20/elytron-new-security-framework-wildfly-jboss-eap/" data-a2a-title="Elytron: A New Security Framework in WildFly/JBoss EAP"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/20/elytron-new-security-framework-wildfly-jboss-eap/"&gt;Elytron: A New Security Framework in WildFly/JBoss EAP&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/01PxDs6LkS0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Elytron is a new security framework that ships with WildFly version 10 and Red Hat JBoss Enterprise Application Platform (EAP) 7.1. This project is a complete replacement of PicketBox and JAAS. Elytron is a single security framework that will be usable for securing management access to the server and for securing applications deployed in WildFly. You can still use the [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/20/elytron-new-security-framework-wildfly-jboss-eap/"&gt;Elytron: A New Security Framework in WildFly/JBoss EAP&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/20/elytron-new-security-framework-wildfly-jboss-eap/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">476417</post-id><dc:creator>Siddhartha De</dc:creator><dc:date>2018-04-20T10:55:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/20/elytron-new-security-framework-wildfly-jboss-eap/</feedburner:origLink></entry><entry><title>bpmNEXT 2018 day 3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/LHJSdpAIEPE/bpmnext-2018-day-3.html" /><category term="bpmNEXT" scheme="searchisko:content:tags" /><category term="Demo" scheme="searchisko:content:tags" /><category term="event" scheme="searchisko:content:tags" /><category term="feed_group_name_jbpm" scheme="searchisko:content:tags" /><category term="feed_name_kverlaen" scheme="searchisko:content:tags" /><category term="Presentation" scheme="searchisko:content:tags" /><author><name>Kris Verlaenen</name></author><id>searchisko:content:id:jbossorg_blog-bpmnext_2018_day_3</id><updated>2018-04-19T18:58:53Z</updated><published>2018-04-19T18:58:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div style="text-align: justify;"&gt;&lt;b&gt;When Artificial Intelligence meets Process-Based Applications&lt;/b&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;i&gt;Nicolas Chabanoles and Nathalie Cotté - Bonitasoft&lt;/i&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;Rather than just relying on reporting for insight in your processes, adding Artificial Intelligence is taking it a step further towards being able to create a shorter feedback look, do predictions, etc.&amp;nbsp; Using a custom loan request application, they show how data is extracted from the database into ElasticSearch, after which they build a predictive model from that.&amp;nbsp; Using process mining techniques they apply time-based analysis to predict the likeliness of certain requests still able to reach their SLA (or not).&amp;nbsp; Based on that information the operational people can decide which requests to prioritize.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;b&gt;Understanding Your Models and What They Are Trying to Tell You&lt;/b&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;i&gt;Tim Stephenson - Know Process&lt;/i&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;Searching and looking into your process models can become complex if you have lots of processes.&amp;nbsp; By indexing these processes, a quite nifty query language can then be used to go and query those models.&amp;nbsp; Search for processes, data and resource involved, etc.&amp;nbsp; While the theory sounds nice, in reality it didn't always seem to be that simple.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;b&gt;Exploiting Cloud Infrastructure for Efficient Business Process Execution&lt;/b&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;i&gt;Kris Verlaenen - Red Hat&lt;/i&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;My own presentation, about executing processes in a cloud environment in a distributed manner.&amp;nbsp; We've introduced services like controllers (to keep track of your engines running everywhere and manage them), and smart routers (to route requests to the right engine and aggregate data across them).&amp;nbsp; Our monitoring console allows you to connect to any engine out there (in this case a engine embedded in a sample order application deployed on a Minishift instance).&amp;nbsp; In the demo I showed how you can then update the SLA expectations of the embedded process, and after deploying this new version of the project monitor for changes.&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;b&gt;Dynamic Work Assignment&lt;/b&gt;&lt;/div&gt;&lt;div style="text-align: justify;"&gt;&lt;i&gt;Lloyd Dugan - Serco&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;In the context of Obamacare, Lloyd presented a use case of improving task assignment by scoring tasks (based on eligibility, severity, etc.) and assigning them to the right people.&amp;nbsp; Replacing a model where tasks were mostly just kept in queues and workers needed to go and go pick them up and choose, it allows tasks to be put "on hold" so they temporarily would not show up in the queues.&lt;br /&gt;Geoffrey would have loved to see this, as I think the combination of process and rules was nice for solving this issue, but imho it's missing an actual constraint solving component (like OptaPlanner) to do the score calculations.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/LHJSdpAIEPE" height="1" width="1" alt=""/&gt;</content><summary>When Artificial Intelligence meets Process-Based Applications Nicolas Chabanoles and Nathalie Cotté - Bonitasoft Rather than just relying on reporting for insight in your processes, adding Artificial Intelligence is taking it a step further towards being able to create a shorter feedback look, do predictions, etc.  Using a custom loan request application, they show how data is extracted from the d...</summary><dc:creator>Kris Verlaenen</dc:creator><dc:date>2018-04-19T18:58:00Z</dc:date><feedburner:origLink>http://kverlaen.blogspot.com/2018/04/bpmnext-2018-day-3.html</feedburner:origLink></entry><entry><title>An API Journey: From Idea to Deployment the Agile Way–Part II</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/0aVXlLQlEjM/" /><category term="Microservices" /><category term="Modern App Dev" /><category term="3scale" /><category term="API" /><category term="ci/cd" /><category term="design" /><category term="microservices" /><category term="mock" /><category term="OpenShift Container Platform" /><category term="testing" /><author><name>Laurent Broudoux</name></author><id>https://developers.redhat.com/blog/?p=474567</id><updated>2018-04-19T18:00:50Z</updated><published>2018-04-19T18:00:50Z</published><content type="html">&lt;p&gt;&lt;span style="font-weight: 400"&gt;This is part II of a three-part series describing a proposed approach for an agile API lifecycle from ideation to production deployment. If you missed part 1 or need a refresher, please take some time to read &lt;a href="https://developers.redhat.com/blog/2018/04/11/api-journey-idea-deployment-agile-part1/"&gt;part I&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;This series is coauthored with Nicolas Massé, also a Red Hatter, and it is based on our own real-life experiences from our work with the Red Hat customers we’ve met.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;In part I, we explored how ACME Inc. is taking an agile API journey for its new &lt;code&gt;Beer Catalog API&lt;/code&gt;, and ACME completed the API ideation, contract design, and sampling stages. Let&amp;#8217;s go now to mocking.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span id="more-474567"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400"&gt;Milestone 3: API Mocks and Ready-to-Use Tests&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;We took time in part 1 illustrating samples and defining complementary expectations for our API or microservices. Is it all worth it? Yes, definitely. The first reason is because samples and expectations can be helpful documentation allowing you to understand the real-life usages of an API. The second is that we will be able to use them to speed up things and parallelize development. Let’s see how we can do that.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;The purpose of this stage is to be able to:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Transform provided samples into ready-to-use mocks.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Reuse samples and expectations as a real test suite for future API implementation.&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478567 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-mocking-1024x607.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-mocking-300x178.png" alt="API mocking stage" width="300" height="178" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-mocking-300x178.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-mocking-768x455.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-mocking-1024x607.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-mocking.png 1262w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Here again, there’s the “local” versus “team” approaches discussion regarding tooling.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;The “local” approach for producing mocks is really easy to set up and use from a developer perspective. It is implemented by many tools such as &lt;/span&gt;&lt;a href="https://hoverfly.io/"&gt;&lt;span style="font-weight: 400"&gt;Hoverfly&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; and &lt;/span&gt;&lt;a href="http://wiremock.org/"&gt;&lt;span style="font-weight: 400"&gt;WireMock&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;. You can also argue that some development tools are so easy to use that mocking is just a few lines of code. That may be true, but misses two important points, in my opinion.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;The first is about the documentation and communication purposes behind mocks. They’re also here to help us understand APIs so they should be largely reachable. &lt;/span&gt;&lt;span style="font-weight: 400"&gt;The second is about the lifetime of a mock. Mocks managed by developers are very useful for their project scope during integration tests. However, the most useful mocks are those that stay live, ready to use for every consumer that will arise in the coming weeks, months and years.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;The “team” approach provides these benefits. Some tools such as &lt;/span&gt;&lt;a href="https://cloud.hoverfly.io"&gt;&lt;span style="font-weight: 400"&gt;Hoverfly Cloud&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; or even &lt;/span&gt;&lt;a href="https://www.getpostman.com/docs/postman/mock_servers/setting_up_mock"&gt;&lt;span style="font-weight: 400"&gt;Postman mocks&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; allow this team approach. However, we still think there are missing some points, because being SaaS-only solutions, they are devoted to REST APIs only and deal only with the mocking part, not the testing part.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Here again, we propose having a look at &lt;/span&gt;&lt;a href="http://microcks.github.io/"&gt;&lt;span style="font-weight: 400"&gt;Microcks&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; for this stage. Microks is able to live in your data center and take over your REST APIs and your—not so legacy—existing SOAP web services. Microcks also supports testing your API implementation, as explained below.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Back to our ACME use case: the only thing to do in Microcks is to register the URL of the Postman Collection file in your Git repository. Microcks has this concept of a &lt;em&gt;job&lt;/em&gt; than can be scheduled or triggered to refresh mocks and expectations definitions within its repository.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478577 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-add-job-1024x838.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-add-job-1024x838.png" alt="Microcks add job form" width="1024" height="838" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-add-job-1024x838.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-add-job-300x245.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-add-job-768x628.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-add-job.png 1310w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Once the job is created and activated, it scans the specified URL. That way, it is able to discover your API or service definitions. We instantly get a full description of the API and meaningful attached samples. Mocks are deployed instantly and specific endpoints are provided for every new API and its operations.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478587 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-beer-api-details-1024x891.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-beer-api-details-1024x891.png" alt="Microcks beer API details" width="1024" height="891" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-beer-api-details-1024x891.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-beer-api-details-300x261.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-beer-api-details-768x668.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Retrieving the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;Mocks URL&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; information and appending it to the server base URL, we can now check that we have ready-to-use mocks.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;We are able to list all the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;beers&lt;/span&gt;&lt;span style="font-weight: 400"&gt; in the catalog—using pagination options.&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl 'http://microcks.example.com/rest/Beer%20Catalog%20API/0.9/beer?page=0' [ { "name": "Rodenbach", "country": "Belgium", "type": "Brown ale", "rating": 4.2, "status": "available" }, { "name": "Westmalle Triple", "country": "Belgium", "type": "Trappist", "rating": 3.8, "status": "available" }, { "name": "Weissbier", "country": "Germany", "type": "Wheat", "rating": 4.1, "status": "out_of_stock" } ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;We can then retrieve only one &lt;/span&gt;&lt;span style="font-weight: 400"&gt;beer&lt;/span&gt;&lt;span style="font-weight: 400"&gt; resource using its name:&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl 'http://microcks.example.com/rest/Beer%20Catalog%20API/0.9/beer/Weissbier' { "name": "Weissbier", "country": "Germany", "type": "Wheat", "rating": 4.1, "status": "out_of_stock" }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;And we can also retrieve only the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;beers&lt;/span&gt;&lt;span style="font-weight: 400"&gt; having the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;available&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; status:&lt;/span&gt;&lt;span style="font-weight: 400"&gt;                          &lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ curl 'http://microcks.example.com/rest/Beer%20Catalog%20API/0.9/beer/findByStatus/available' [ { "name": "Rodenbach", "country": "Belgium", "type": "Brown ale", "rating": 4.2, "status": "available" }, { "name": "Westmalle Triple", "country": "Belgium", "type": "Trappist", "rating": 3.8, "status": "available" } ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Notice on the Microcks API details page the orange &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;NEW TEST...&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; button; we will use it in the next stage. We are now ready to start two development streams in parallel: &lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;span style="font-weight: 400"&gt;The development of the API full implementation &lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span style="font-weight: 400"&gt;The development of any of the consumers &lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Consumers will use the mocks exposed by Microcks to have a taste of future implementation. At next stage, we will focus on API implementation and see how the expectations we set up will be used to test and ensure the implementation is respecting them.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400"&gt;Milestone 4: Developing, Deploying, and Testing&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Developing, deploying, and testing is the most obvious stage of this API journey, and you probably already have chosen your stack. However, we think it may be helpful to highlight some requirements of modern application development and deployment. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;We can set up the assumption that today, each new application supporting API should be a cloud-ready application. By &lt;em&gt;cloud-ready&lt;/em&gt;, we expect that it should have the following properties:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;The ability to adapt dynamically to the load&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;A flexible and centralized configuration&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;A dependency discovery mechanism&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;A native load-balancing mechanism for communicating&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Strong resiliency, monitoring, and observability&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Automatic log and distributed traces collection&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;All those features should be at hand, integrated into the developer experience. They are the reason why PaaS solutions based on &lt;/span&gt;&lt;a href="https://kubernetes.io/"&gt;&lt;span style="font-weight: 400"&gt;Kubernetes&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; container orchestrator are today the best choice for building and deploying API implementations. The purpose of this stage is to make API deployment fast and repeatable, so that we can test different environments with our expectations.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478607 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-deployment-1024x531.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-deployment-300x156.png" alt="API deployment stage" width="300" height="156" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-deployment-300x156.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-deployment-768x398.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-deployment-1024x531.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-deployment.png 1288w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;At this stage, ACME has chosen the Spring Boot framework as its development stack and will deploy it onto &lt;/span&gt;&lt;a href="https://www.openshift.com/"&gt;&lt;span style="font-weight: 400"&gt;OpenShift&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;, the Red Hat PaaS solution based on Kubernetes. Once you get your &lt;/span&gt;&lt;span style="font-weight: 400"&gt;OpenShift instance ready, we’re going to create a new project for hosting our development environment of the ACME API implementation. This is as simple as executing an &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;oc&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; command, or it can be done through the OpenShift web console:&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;oc new-project beer-catalog-dev --display-name="Beer Catalog (DEV)"&lt;/code&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Having a dedicated project in OpenShift allows it to be isolated (in terms of network, user authorization, and resource consumption) from another project. You can now easily deploy your application, choosing &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;Red Hat OpenJDK 8&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; from the catalog and filling in the advanced properties.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478627 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-new-java-app-1024x636.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-new-java-app-1024x636.png" alt="OpenShift new Java app form" width="1024" height="636" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-new-java-app-1024x636.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-new-java-app-300x186.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-new-java-app-768x477.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;You’ll notice that API implementation is located in a &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;/beer-catalog-demo/api-implementation&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; directory within the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;https://github.com/microcks/api-lifecycle&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; GitHub repository. Even if OpenShift is running containers at the end, it allows you to simply deploy your application from source code. It is handing to you all the bits and bytes of application build and containerization before the real deployment occurs (this process is called &amp;#8220;source to image&amp;#8221; in OpenShift).&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;After some minutes, you should have a pod running and all the networking stuff initialized, as shown in the screenshot below:&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478647 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-1024x494.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-1024x494.png" alt="OpenShift app deployment" width="1024" height="494" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-1024x494.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-300x145.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-768x371.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;It is now time to test the ACME implementation of the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;Beer Catalog API&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; version 0.9 to see if it’s compliant with the defined endpoints and expectations. So let’s get back to Microcks so you can now use the orange &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;NEW TEST…&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; button.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Requesting a &lt;/span&gt;&lt;span style="font-weight: 400"&gt;new test&lt;/span&gt;&lt;span style="font-weight: 400"&gt; in Microcks allows you to set up two test properties: the endpoint URL that should be evaluated and the runner (the test strategy) that the test should apply.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478657 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-new-test-form-1024x776.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-new-test-form-1024x776.png" alt="Microcks new test form" width="1024" height="776" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-new-test-form-1024x776.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-new-test-form-300x227.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-new-test-form-768x582.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Microcks makes different strategies available out of the box for tests. You can choose testing only the endpoints (that is, a smoke test) up to testing the compliance of response messages from the implementation. The &lt;/span&gt;&lt;span style="font-weight: 400"&gt;Postman&lt;/span&gt;&lt;span style="font-weight: 400"&gt; strategy simply reuses the expectations we have set up during the staging phase in Milestone 2.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;The test can now be launched. You’ll land on a summary page that will refresh until the test is completely done (success or failure). You can see that in our case, it’s all green, indicating success.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478667 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-test-result-1024x909.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-test-result-1024x909.png" alt="Microcks test results" width="1024" height="909" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-test-result-1024x909.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-test-result-300x266.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-test-result-768x682.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;You can then access the detailed f&lt;/span&gt;&lt;span style="font-weight: 400"&gt;ull results&lt;/span&gt;&lt;span style="font-weight: 400"&gt; of the test, which leads you to a page where you can also check and grab the payload and headers exchanged with your tested API implementation.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478677 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-full-test-result-1024x881.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-full-test-result-1024x881.png" alt="Microcks test full result" width="1024" height="881" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-full-test-result-1024x881.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-full-test-result-300x258.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/microcks-full-test-result-768x661.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;We are now confident in the implementation of ACME&amp;#8217;s API and can continue the journey.&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400"&gt;Milestone 5: Continuous Testing of the API Implementation&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Launching the test manually is acceptable one or two times. But it would be really neat to have this done in an automated way. Moreover, you should consider launching new tests automatically from your continuous integration/continuous delivery (CI/CD) pipeline each time you build and deploy a new version of your implementation.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;What we achieve in this stage is a seamless integration of the API testing within your automated build, deployment, and delivery flow, as suggested in the schema below:&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478687 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-testing-1024x503.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-testing-300x147.png" alt="API Testing stage" width="300" height="147" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-testing-300x147.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-testing-768x377.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-testing-1024x503.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/api-testing.png 1348w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Luckily, ACME has the right set of tools for doing that. What we are going to set up now is a new production environment for our API implementation. Right next to the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;beer-catalog-dev&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; environment we created earlier in OpenShift, we are going to create a &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;beer-catalog-prod&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; environment. We’re also going to declare a CI/CD pipeline within OpenShift. This pipeline will automatically connect to Microcks in order to check that the test is OK before deploying into production.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Before starting, let’s review some prerequisite setups and concepts. The CI/CD pipelines in OpenShift are implemented using &lt;/span&gt;&lt;a href="https://jenkins.io/"&gt;&lt;span style="font-weight: 400"&gt;Jenkins&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;—a de facto standard for managing pipelines. OpenShift provides certified images and templates of Jenkins that you can customize. And we have used that feature to set up a Jenkins instance that embeds the &lt;/span&gt;&lt;a href="https://github.com/microcks/microcks-jenkins-plugin"&gt;&lt;span style="font-weight: 400"&gt;Microcks Jenkins plug-in&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;. Plug-in installation can be done in many way, but we provide a &lt;/span&gt;&lt;a href="http://microcks.github.io/automating/jenkins/#jenkins-info"&gt;&lt;span style="font-weight: 400"&gt;Jenkins master configuration&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt; to do that easily. We assume you have set up a &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;jenkins&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; service instance (that has this plug-in) in a dedicated &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;microcks&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; OpenShift project.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Because doing everything by hand is cumbersome and error-prone, we provide a &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;deploy-pipeline.sh&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; script in the &lt;/span&gt;&lt;a href="https://github.com/microcks/api-lifecycle/tree/master/beer-catalog-demo"&gt;&lt;span style="font-weight: 400"&gt;GitHub repository&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400"&gt;. So just execute this script once you are logged on to your OpenShift environment, and you should get a new pipeline definition within your &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;microcks&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; project.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478697 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-pipeline-1024x227.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-pipeline-1024x227.png" alt="" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-pipeline-1024x227.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-pipeline-300x66.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-pipeline-768x170.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;You might just review the configuration of this pipeline before actually starting it so you understand what’s going on. In the &lt;code&gt;Configuration&lt;/code&gt; tag of the web console, you’ll find the following description:&lt;/span&gt;&lt;/p&gt; &lt;pre&gt;&lt;code&gt;node('maven') { stage ('buildInDev') { openshiftBuild(buildConfig: 'beer-catalog-impl', namespace: 'beer-catalog-dev', showBuildLogs: 'true') } stage ('deployInDev') { openshiftDeploy(namespace: 'beer-catalog-dev', deploymentConfig: 'beer-catalog-impl') } stage ('testInDev') { // Add Microcks test here. microcksTest(apiURL: 'http://microcks.example.com/api', serviceId: 'Beer Catalog API:0.9', testEndpoint: 'http://beer-catalog-impl-beer-catalog-dev.52.174.149.59.nip.io/api/', runnerType: 'POSTMAN', verbose: 'true') } stage ('promoteToProd') { openshiftTag(namespace: 'beer-catalog-dev', sourceStream: 'beer-catalog-impl', sourceTag: 'latest', destinationStream: 'beer-catalog-impl', destinationTag: 'promoteToProd') } stage ('approval') { input 'Do you want to deploy this application in production?' } stage ('deployToProd') { openshiftDeploy(deploymentConfig: 'beer-catalog-impl', namespace: 'beer-catalog-prod') openshiftScale(deploymentConfig: 'beer-catalog-impl', namespace: 'beer-catalog-prod', replicaCount: '2') } }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Notice the important part here: it&amp;#8217;s the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;microcksTest()&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; directive. That is the Microcks plug-in for Jenkins that just delegates the execution of a new test to the Microcks server using the mentioned &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;apiURL&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt;. The new test is about our &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;Beer Catalog API&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; version &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;0.9&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; on the development &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;testEndpoint&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; and uses the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;POSTMAN&lt;/code&gt;&lt;/span&gt; &lt;span style="font-weight: 400"&gt;&lt;code&gt;runnerType&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt;. So basically, we found the same arguments as with our earlier manual test.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;In the pipeline definition, this test will be run after each deployment on the development environment. The success of the test will allow the pipeline to continue and promote the API implementation into production.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;After running the pipeline, you should get the following status on the &lt;/span&gt;&lt;span style="font-weight: 400"&gt;&lt;code&gt;beer-catalog-prod&lt;/code&gt;&lt;/span&gt;&lt;span style="font-weight: 400"&gt; environment: two replicas of the same application pod.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-478717 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-prod-1024x399.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-prod-1024x399.png" alt="OpenShift deployment prod" width="1024" height="399" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-prod-1024x399.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-prod-300x117.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/04/openshift-deployment-prod-768x299.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /&gt;&lt;/p&gt; &lt;h2&gt;&lt;span style="font-weight: 400"&gt;Key Takeaways&lt;/span&gt;&lt;/h2&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;In this part II of the series, we have seen how ACME pursued its API journey through the following three stages:&lt;/span&gt;&lt;/p&gt; &lt;ul&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;API mocks exposition so that future consumers of the API can start earlier their development.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Development and deployment on a modern container platform for easy deployment. We can then run manual tests to harden the implementation regarding complementary expectations.&lt;/span&gt;&lt;/li&gt; &lt;li style="font-weight: 400"&gt;&lt;span style="font-weight: 400"&gt;Set up of continuous testing that allows us to reuse the samples and tests in a continuous integration and delivery pipeline.&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span style="font-weight: 400"&gt;Stay tuned for part III, in which you will learn how to secure the APIs using API management and much more.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;linkname=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Fapi-journey-idea-deployment-agile-way-part2%2F&amp;#38;title=An%20API%20Journey%3A%20From%20Idea%20to%20Deployment%20the%20Agile%20Way%E2%80%93Part%20II" data-a2a-url="https://developers.redhat.com/blog/2018/04/19/api-journey-idea-deployment-agile-way-part2/" data-a2a-title="An API Journey: From Idea to Deployment the Agile Way–Part II"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/19/api-journey-idea-deployment-agile-way-part2/"&gt;An API Journey: From Idea to Deployment the Agile Way&amp;#8211;Part II&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/0aVXlLQlEjM" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This is part II of a three-part series describing a proposed approach for an agile API lifecycle from ideation to production deployment. If you missed part 1 or need a refresher, please take some time to read part I. This series is coauthored with Nicolas Massé, also a Red Hatter, and it is based on [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/19/api-journey-idea-deployment-agile-way-part2/"&gt;An API Journey: From Idea to Deployment the Agile Way&amp;#8211;Part II&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/19/api-journey-idea-deployment-agile-way-part2/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">474567</post-id><dc:creator>Laurent Broudoux</dc:creator><dc:date>2018-04-19T18:00:50Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/19/api-journey-idea-deployment-agile-way-part2/</feedburner:origLink></entry><entry><title>Expanding architectural choices to better arm Red Hat Enterprise Linux developers</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/hOk9kDccilI/" /><category term="Announcement" /><category term="Developer Tools" /><category term="Red Hat Developer Toolset" /><category term="Red Hat Enterprise Linux" /><category term="Red Hat Software Collections" /><category term="ARM" /><category term="arm64" /><category term="developer" /><category term="developer toolset" /><category term="dts" /><category term="RHEL" /><category term="RHSCL" /><category term="software collections" /><author><name>Yan Fisher</name></author><id>https://developers.redhat.com/blog/?p=487147</id><updated>2018-04-19T16:00:04Z</updated><published>2018-04-19T16:00:04Z</published><content type="html">&lt;p&gt;Red Hat Enterprise Linux continues to deliver the best possible experience for enterprise system administrators and developers, as well as provide a solid foundation for moving workloads into both public and private clouds. One of the ways to enable such ubiquity is &lt;a href="https://www.redhat.com/en/blog/open-across-all-architectures-introducing-red-hat’s-multi-architecture-initiative"&gt;Red Hat’s multi-architecture initiative&lt;/a&gt;, which focuses on bringing Red Hat’s software portfolio to different hardware architectures.&lt;/p&gt; &lt;p&gt;Last week, &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-strengthens-hybrid-clouds-backbone-latest-version-red-hat-enterprise-linux"&gt;Red Hat Enterprise Linux 7.5 went live&lt;/a&gt;. It brought forward several improvements relevant to developers and system administrators such as advanced GUI system management via the Cockpit console, which should help new Linux administrators, developers, and Windows users to perform expert tasks without having to get into the command line.&lt;/p&gt; &lt;p&gt;This release also marks a new milestone for Red Hat Enterprise Linux: all supported architectures are now simultaneously enabled. The list of supported architectures includes x86_64, PowerPC Big Endian and Little Endian, s390x, and the more recently introduced &lt;a href="https://www.redhat.com/en/blog/red-hat-introduces-arm-server-support-red-hat-enterprise-linux"&gt;64-bit Arm&lt;/a&gt; and &lt;a href="https://www.redhat.com/en/blog/red-hat-launches-support-latest-ibm-hardware-red-hat-enterprise-linux"&gt;IBM POWER9&lt;/a&gt; architectures.&lt;span id="more-487147"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Moreover, we are making new architectures even more accessible to developers by including the operating system for 64-bit Arm servers in the free Developer subscription. You can now &lt;a href="https://developers.redhat.com/products/rhel/download/"&gt;download Red Hat Enterprise Linux for ARM directly&lt;/a&gt; from developers.redhat.com. If you don’t have an account, join the Red Hat Developer Program; &lt;a href="http://developers.redhat.com/register"&gt;registration is easy and free&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;To save you some headaches in getting this OS version installed and running, you should be aware that not all Arm systems out there are designed to be true enterprise-grade servers. Our OS is focused on enabling Arm server hardware that supports &lt;a href="https://en.wikipedia.org/wiki/Server_Base_System_Architecture"&gt;SBSA&lt;/a&gt; and &lt;a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0044b/index.html"&gt;SBBR&lt;/a&gt; standards and that boot only with &lt;a href="https://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface"&gt;UEFI&lt;/a&gt;. This means that, by design, you would not be able to run this OS on &lt;a href="https://en.wikipedia.org/wiki/Raspberry_Pi"&gt;Raspberry Pi&lt;/a&gt; or similar lightweight devices.&lt;/p&gt; &lt;p&gt;We are looking forward to seeing more enterprise developers grabbing these bits for their software porting and testing efforts, especially since the included user-land tools and utilities are standard across all existing Red Hat Enterprise Linux 7 releases. The big news with Red Hat Enterprise Linux for ARM is the inclusion of the 4.14 Linux kernel. And, if you are in need of the newer software components or compilers, be sure to grab the latest release of the &lt;a href="https://developers.redhat.com/products/developertoolset/overview/"&gt;Developer Toolset&lt;/a&gt; and &lt;a href="https://developers.redhat.com/products/softwarecollections/overview/"&gt;Software Collections&lt;/a&gt; that are available free of charge across all supported architectures, including 64-bit Arm.&lt;/p&gt; &lt;p&gt;Most importantly, whatever you decide to do, have fun doing it!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;linkname=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F04%2F19%2Frhel-expanding-architectural-choices-arm-developers%2F&amp;#38;title=Expanding%20architectural%20choices%20to%20better%20arm%20Red%20Hat%20Enterprise%20Linux%20developers" data-a2a-url="https://developers.redhat.com/blog/2018/04/19/rhel-expanding-architectural-choices-arm-developers/" data-a2a-title="Expanding architectural choices to better arm Red Hat Enterprise Linux developers"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/19/rhel-expanding-architectural-choices-arm-developers/"&gt;Expanding architectural choices to better arm Red Hat Enterprise Linux developers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/hOk9kDccilI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Red Hat Enterprise Linux continues to deliver the best possible experience for enterprise system administrators and developers, as well as provide a solid foundation for moving workloads into both public and private clouds. One of the ways to enable such ubiquity is Red Hat’s multi-architecture initiative, which focuses on bringing Red Hat’s software portfolio to [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/04/19/rhel-expanding-architectural-choices-arm-developers/"&gt;Expanding architectural choices to better arm Red Hat Enterprise Linux developers&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2018/04/19/rhel-expanding-architectural-choices-arm-developers/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">487147</post-id><dc:creator>Yan Fisher</dc:creator><dc:date>2018-04-19T16:00:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/04/19/rhel-expanding-architectural-choices-arm-developers/</feedburner:origLink></entry><entry><title>This week in JBoss, 19th April 2018 - it's BPM week!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/nCa9oImPBDY/this-week-in-jboss-19th-april-2018-its-bpm-week" /><category term="BPM" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="hibernate ogm" scheme="searchisko:content:tags" /><category term="istio" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Mark Little</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_19th_april_2018_it_s_bpm_week</id><updated>2018-04-19T13:06:15Z</updated><published>2018-04-19T13:06:00Z</published><content type="html">&lt;!-- [DocumentBodyStart:e11ad022-53cd-4d6c-b6c9-3ef17d33d3b1] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;There has been a lot of BPM related activity this relatively quiet week.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;jBPM Lead Kris Verlaenen has written an &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/bpmnext_2018_kicking_off" rel="nofollow"&gt;article&lt;/a&gt; about his attendance of bpmNEXT 2018. In fact it was such a good day 1 that he had to span it across two &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/bpmnext_2018_part_2" rel="nofollow"&gt;articles&lt;/a&gt;! Kris also followed up with a &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/bpmnext_2018_day_2" rel="nofollow"&gt;couple&lt;/a&gt; of entries on &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/bpmnext_2018_day_2_part_2" rel="nofollow"&gt;day 2&lt;/a&gt; activities. Meanwhile Edson Tirelli has written a complimentary piece that &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/bpmnext_2018_day_1_videos_are_already_online" rel="nofollow"&gt;points out videos&lt;/a&gt; to the various sessions so everyone can enjoy.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Also this week Eric has been talking about how easy it is to install &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/cloud_happiness_how_to_install_new_openshift_container_platform_3_9_in_just_minutes" rel="nofollow"&gt;OpenShift Container Platform 3.9&lt;/a&gt; as well as part 3 of his series on the &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/inside_open_innovation_labs_residency_part_3" rel="nofollow"&gt;Open Innovation Labs residencies&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Christian &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/our_book_has_been_released_introducing_istio_service_mesh_for_microservices" rel="nofollow"&gt;writes about the book&lt;/a&gt; he and Burr Sutter have written about Istio Service Mesh and which has just been released. Congrats guys!&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Finally &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/hibernate_ogm_5_4_0_alpha1_is_out" rel="nofollow"&gt;Hibernate OGM 5.4.0 Alpha 1&lt;/a&gt; is out and the Keycloak team are conducting a &lt;a class="jive-link-external-small" href="https://planet.jboss.org/post/keycloak_questionnaire" rel="nofollow"&gt;questionnaire&lt;/a&gt; for users so please look at it.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;OK that's it for this week!&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:e11ad022-53cd-4d6c-b6c9-3ef17d33d3b1] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/nCa9oImPBDY" height="1" width="1" alt=""/&gt;</content><summary>There has been a lot of BPM related activity this relatively quiet week.   jBPM Lead Kris Verlaenen has written an article about his attendance of bpmNEXT 2018. In fact it was such a good day 1 that he had to span it across two articles! Kris also followed up with a couple of entries on day 2 activities. Meanwhile Edson Tirelli has written a complimentary piece that points out videos to the variou...</summary><dc:creator>Mark Little</dc:creator><dc:date>2018-04-19T13:06:00Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2018/04/19/this-week-in-jboss-19th-april-2018-its-bpm-week</feedburner:origLink></entry></feed>
